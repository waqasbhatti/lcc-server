This page describes the LCC server's text light curve format. The files
generated by the server are in a separator-delimited CSV-like format with a
header at the top of the file marked out by comment characters at the beginning
of each line. By default, the separator used is the comma character: `,`. The
default comment character is the octothorpe: `#`.

[TOC]

## Light curve format

The file contains the following sections.

### The format descriptor at the top of the file

```
LCC-CSVLC-V1
#
,
```

### Object and light curve metadata in JSON format

```
# OBJECT METADATA
# {
#   "objectid": {
#     "val": "HAT-198-0835489",
#     "desc": "object ID"
#   },
#   "ra": {
#     "val": 285.93812,
#     "desc": "RA [deg]"
#   },
#   "decl": {
#     "val": 34.7304,
#     "desc": "Dec [deg]"
#   },
# ... more metadata keys as specified by input light curve format...
```

### Column descriptions in JSON format

```
# COLUMN DEFINITIONS
# {
#   "rjd": {
#     "colnum": 0,
#     "dtype": "f8",
#     "desc": "time of observation in Reduced Julian date (JD = 2400000.0 + RJD)"
#   },
#   "bjd": {
#     "colnum": 1,
#     "dtype": "f8",
#     "desc": "time of observation in Baryocentric Julian date (BJD_TDB)"
#   },
#   "net": {
#     "colnum": 2,
#     "dtype": "i8",
#     "desc": "network of telescopes observing this target"
#   },
# ... more column descriptions as defined in the input light curve format...
```

### The actual light curve columns

Note that missing number values are denoted by `nan` and missing string values
are blank characters.

```
# LIGHTCURVE
53878.9490550,2453878.9517626,HN,5,145195,,1,nan,G19123730_198,object,4,300.000,570,nan,D20,0.17,nan,nan,nan,nan,,nan,nan,nan,nan,nan,-0.07961,-0.06382,-0.06494,0.02294,0.02294,0.02294,G,G,G,0.02080,0.03120,0.01870,0.05164,0.06874,0.05119,nan,nan,0.03638
53878.9529262,2453878.9556339,HN,5,145196,,1,nan,G19123730_198,object,4,300.000,570,nan,D20,0.17,nan,nan,nan,nan,nan,nan,nan,nan,nan,-0.09286,-0.10065,-0.12399,0.02302,0.02302,0.02302,G,G,G,-0.01290,-0.01650,-0.04400,0.03095,0.02510,-0.00138,nan,nan,0.00759
53878.9568036,2453878.9595115,HN,5,145197,,1,nan,G19123730_198,object,4,300.000,570,nan,D20,0.17,nan,nan,nan,nan,nan,nan,nan,nan,nan,-0.06757,-0.06750,-0.07534,0.03112,0.03112,0.03112,G,G,G,0.00710,0.01410,0.00380,0.03422,0.04238,0.03238,nan,nan,0.02745
... more light curve lines ...
```

## Reading the light curves

Since the light curve files are text based, they should be readable by most
editors and programming languages. By default, the files come in gzipped format
and the file names are of the form:

```
<objectid>-csvlc.gz
```

One can use standard UNIX tools like `zless`, e.g.:

```bash
$ zless /path/to/<objectid>-csvlc.gz
```

### Using numpy

Using Python and numpy also works well, given the information on the column
number and dtype in the file headers, e.g.:

```python

import numpy as np
import gzip

with gzip.open(lcfile,'rb') as infd:
    recarr = np.genfromtxt(
        infd,
        skip_header=3,
        comments='#',
        delimiter=',',
        usecols=[0,30,37],
        autostrip=True,
        names=['rjd','aie_000','aep_000'],
        dtype='f8,f8,f8'
    )
```

### The astrobase `hatlc` module

CSV light curve reader functions are implemented in the
[astrobase](https://github.com/waqasbhatti/astrobase) Python package that
contains other useful light curve handling tools. The module to use from that
package is
[hatlc.py](https://github.com/waqasbhatti/astrobase/blob/master/astrobase/hatsurveys/hatlc.py). You
can use it as a standalone module by downloading it to somewhere in your
`PYTHONPATH` or install the **astrobase** package using `pip`.

To read the light curve using `hatlc.py`:

```python
# if you have the hatlc.py module in your current directory or PYTHONPATH
import hatlc

# or if you're using astrobase
from astrobase.hatsurveys import hatlc

# read in a light curve file to a Python dict
lcd = hatlc.read_csvlc('/path/to/<objectid>-csvlc.gz')

# get times, mags, and errs from columns and read into numpy arrays
times, mags, errs = lcd['rjd'], lcd['atf_000'], lcd['aie_000']

# get a description of the object and light curve metadata
hatlc.describe(lcdict)
```

You can also use `hatlc.py` from the command line. If you downloaded just the
module itself, make the module executable with e.g. `chmod u+x hatlc.py` and
then use `./hatlc.py`. If you installed the **astrobase** package, the script
will already be in your `$PATH` as `hatlc`.

```
$ hatlc --help

usage: hatlc.py [-h] [--describe] hatlcfile

read a HAT LC of any format and output to stdout

positional arguments:
  hatlcfile   path to the light curve you want to read and pipe to stdout

optional arguments:
  -h, --help  show this help message and exit
  --describe  don't dump the columns, show only object info and LC metadata
```


### Example Python code

The following code automatically parses the header and reads the light curve
into a Python dict. This is taken directly from the
[hatlc.py](https://github.com/waqasbhatti/astrobase/blob/master/astrobase/hatsurveys/hatlc.py)
module:

```python

import numpy as np
import gzip

## parsing the header
def parse_csv_header_lcc_csv_v1(headerlines):
    '''
    This parses the header of the LCC CSV V1 LC format.

    '''

    # the first three lines indicate the format name, comment char, separator
    commentchar = headerlines[1]
    separator = headerlines[2]

    headerlines = [x.lstrip('%s ' % commentchar) for x in headerlines[3:]]

    # next, find the indices of the various LC sections
    metadatastart = headerlines.index('OBJECT METADATA')
    columnstart = headerlines.index('COLUMN DEFINITIONS')
    lcstart = headerlines.index('LIGHTCURVE')

    metadata = ' ' .join(headerlines[metadatastart+1:columnstart-1])
    columns = ' ' .join(headerlines[columnstart+1:lcstart-1])
    metadata = json.loads(metadata)
    columns = json.loads(columns)

    return metadata, columns, separator

## reading the light curve
def read_lcc_csvlc(lcfile):
    '''
    This reads a LCC CSVLC.

    '''

    # read in the file and split by lines
    if '.gz' in os.path.basename(lcfile):
        infd = gzip.open(lcfile,'rb')
    else:
        infd = open(lcfile,'rb')

    lctext = infd.read().decode()
    infd.close()

    lctextlines = lctext.split('\n')

    commentchar = lctextlines[1]

    lcstart = lctextlines.index('%s LIGHTCURVE' % commentchar)
    headerlines = lctextlines[:lcstart+1]
    lclines = lctextlines[lcstart+1:]

    metadata, columns, separator = parse_csv_header_lcc_csv_v1(headerlines)

    # break out the objectid and objectinfo
    objectid = metadata['objectid']['val']
    objectinfo = {key:metadata[key]['val'] for key in metadata}

    # figure out the column dtypes
    colnames = []
    colnum = []
    coldtypes = []

    # generate the args for np.genfromtxt
    for k in columns:

        coldef = columns[k]
        colnames.append(k)
        colnum.append(coldef['colnum'])
        coldtypes.append(coldef['dtype'])

    coldtypes = ','.join(coldtypes)

    # read in the LC
    recarr = np.genfromtxt(
        lclines,
        comments=commentchar,
        delimiter=separator,
        usecols=colnum,
        autostrip=True,
        names=colnames,
        dtype=coldtypes
    )

    lcdict = {x:recarr[x] for x in colnames}
    lcdict['objectid'] = objectid
    lcdict['objectinfo'] = objectinfo
    lcdict['columns'] = colnames

    return lcdict
```

Use it like so:

```python

lcdict = read_lcc_csvlc('/path/to/<objectid>-csvlc.gz')
```


## Object metadata key listing

```
            objectid | object ID
               hatid | HAT ID
           twomassid | 2MASS ID
                  ra | RA [deg]
                decl | Dec [deg]
                jmag | 2MASS J
                hmag | 2MASS H
                kmag | 2MASS Ks
                ndet | total number of observations
            stations | observed by telescopes
             network | observation network
         lcapertures | aperture definitions [aperture number, size in pixels]
             filters | telescope filter definitions [code, short name, description]
         lastupdated | last updated at UNIX time
            lcserver | HATLC generator gitref
      lcinstnormcols | light curve normalization description
```

## Light curve column listing

```
column 00 |      rjd | numpy dtype:  f8 | time of observation in Reduced Julian date (JD = 2400000.0 + RJD)
column 01 |      bjd | numpy dtype:  f8 | time of observation in Baryocentric Julian date (BJD_TDB)
column 02 |      net | numpy dtype:  i8 | network of telescopes observing this target
column 03 |      stf | numpy dtype:  i8 | station ID of the telescope observing this target
column 04 |      cfn | numpy dtype:  i8 | camera frame serial number
column 05 |      cfs | numpy dtype: U20 | camera subframe id
column 06 |      ccd | numpy dtype:  i8 | camera CCD position number
column 07 |      prj | numpy dtype: U20 | project ID of this observation
column 08 |      fld | numpy dtype: U20 | observed field name
column 09 |      frt | numpy dtype: U20 | image frame type [flat, object, etc.]
column 10 |      flt | numpy dtype:  i8 | filter ID from the filters table
column 11 |      exp | numpy dtype:  f8 | exposure time for this observation in seconds
column 12 |      tfs | numpy dtype:  i8 | telescope focus setting
column 13 |      ttt | numpy dtype:  f8 | telescope tube temperature [deg]
column 14 |      tms | numpy dtype: U20 | telescope mount state (tracking, drizzling, etc.)
column 15 |      mph | numpy dtype:  f8 | moon phase at this observation
column 16 |      iha | numpy dtype:  f8 | hour angle of object at this observation
column 17 |      izd | numpy dtype:  f8 | zenith distance of object at this observation
column 18 |      xcc | numpy dtype:  f8 | x coordinate on CCD chip
column 19 |      ycc | numpy dtype:  f8 | y coordinate on CCD chip
column 20 |      bgv | numpy dtype:  f8 | sky background measurement around object in ADU
column 21 |      bge | numpy dtype:  f8 | error in sky background measurement in ADU
column 22 |      fsv | numpy dtype:  f8 | source extraction S parameter (1/[the PSF spatial RMS]^2)
column 23 |      fdv | numpy dtype:  f8 | source extraction D parameter (the PSF ellipticity in xy)
column 24 |      fkv | numpy dtype:  f8 | source extraction K parameter (the PSF diagonal ellipticity)
column 25 |  aim_000 | numpy dtype:  f8 | aperture photometry raw instrumental magnitude in aperture 000
column 26 |  aim_001 | numpy dtype:  f8 | aperture photometry raw instrumental magnitude in aperture 001
column 27 |  aim_002 | numpy dtype:  f8 | aperture photometry raw instrumental magnitude in aperture 002
column 28 |  aie_000 | numpy dtype:  f8 | aperture photometry raw instrumental mag error in aperture 000
column 29 |  aie_001 | numpy dtype:  f8 | aperture photometry raw instrumental mag error in aperture 001
column 30 |  aie_002 | numpy dtype:  f8 | aperture photometry raw instrumental mag error in aperture 002
column 31 |  aiq_000 | numpy dtype:  f8 | aperture photometry raw instrumental mag quality flag, aperture 000
column 32 |  aiq_001 | numpy dtype:  f8 | aperture photometry raw instrumental mag quality flag, aperture 001
column 33 |  aiq_002 | numpy dtype:  f8 | aperture photometry raw instrumental mag quality flag, aperture 002
column 34 |  arm_000 | numpy dtype:  f8 | aperture photometry fit magnitude in aperture 000
column 35 |  arm_001 | numpy dtype:  f8 | aperture photometry fit magnitude in aperture 001
column 36 |  arm_002 | numpy dtype:  f8 | aperture photometry fit magnitude in aperture 002
column 37 |  aep_000 | numpy dtype:  f8 | aperture photometry EPD magnitude in aperture 000
column 38 |  aep_001 | numpy dtype:  f8 | aperture photometry EPD magnitude in aperture 001
column 39 |  aep_002 | numpy dtype:  f8 | aperture photometry EPD magnitude in aperture 002
column 40 |  atf_000 | numpy dtype:  f8 | aperture photometry TFA magnitude in aperture 000
column 41 |  atf_001 | numpy dtype:  f8 | aperture photometry TFA magnitude in aperture 001
column 42 |  atf_002 | numpy dtype:  f8 | aperture photometry TFA magnitude in aperture 002
```
